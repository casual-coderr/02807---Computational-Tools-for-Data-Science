{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a73a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c14b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\AppData\\Local\\Temp\\ipykernel_17932\\901575409.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df[\"start_hour\"] = df[\"starttime\"].dt.floor(\"H\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips: 17548339  |  Date span: 2018-01-01 → 2018-12-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>trip_duration_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>2018-01-01 13:50:57.434</td>\n",
       "      <td>2018-01-01 14:07:08.186</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>505.0</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>31956</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>16.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723</td>\n",
       "      <td>2018-01-01 15:33:30.182</td>\n",
       "      <td>2018-01-01 15:45:33.341</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>3255.0</td>\n",
       "      <td>40.750585</td>\n",
       "      <td>-73.994685</td>\n",
       "      <td>32536</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>12.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496</td>\n",
       "      <td>2018-01-01 15:39:18.337</td>\n",
       "      <td>2018-01-01 15:47:35.172</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>525.0</td>\n",
       "      <td>40.755942</td>\n",
       "      <td>-74.002116</td>\n",
       "      <td>16069</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1956</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>8.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306</td>\n",
       "      <td>2018-01-01 15:40:13.372</td>\n",
       "      <td>2018-01-01 15:45:20.191</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>447.0</td>\n",
       "      <td>40.763707</td>\n",
       "      <td>-73.985162</td>\n",
       "      <td>31781</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>5.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>2018-01-01 18:14:51.568</td>\n",
       "      <td>2018-01-01 18:19:57.642</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>40.774667</td>\n",
       "      <td>-73.984706</td>\n",
       "      <td>30319</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 18:00:00</td>\n",
       "      <td>5.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration               starttime                stoptime  \\\n",
       "0           970 2018-01-01 13:50:57.434 2018-01-01 14:07:08.186   \n",
       "1           723 2018-01-01 15:33:30.182 2018-01-01 15:45:33.341   \n",
       "2           496 2018-01-01 15:39:18.337 2018-01-01 15:47:35.172   \n",
       "3           306 2018-01-01 15:40:13.372 2018-01-01 15:45:20.191   \n",
       "4           306 2018-01-01 18:14:51.568 2018-01-01 18:19:57.642   \n",
       "\n",
       "   start_station_id  start_station_latitude  start_station_longitude  \\\n",
       "0              72.0               40.767272               -73.993929   \n",
       "1              72.0               40.767272               -73.993929   \n",
       "2              72.0               40.767272               -73.993929   \n",
       "3              72.0               40.767272               -73.993929   \n",
       "4              72.0               40.767272               -73.993929   \n",
       "\n",
       "   end_station_id  end_station_latitude  end_station_longitude  bikeid  \\\n",
       "0           505.0             40.749013             -73.988484   31956   \n",
       "1          3255.0             40.750585             -73.994685   32536   \n",
       "2           525.0             40.755942             -74.002116   16069   \n",
       "3           447.0             40.763707             -73.985162   31781   \n",
       "4          3356.0             40.774667             -73.984706   30319   \n",
       "\n",
       "     usertype  birth_year  gender          start_hour  trip_duration_min  \n",
       "0  Subscriber        1992       1 2018-01-01 13:00:00          16.166667  \n",
       "1  Subscriber        1969       1 2018-01-01 15:00:00          12.050000  \n",
       "2  Subscriber        1956       1 2018-01-01 15:00:00           8.266667  \n",
       "3  Subscriber        1974       1 2018-01-01 15:00:00           5.100000  \n",
       "4  Subscriber        1992       1 2018-01-01 18:00:00           5.100000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Trips_2018.csv\")\n",
    "\n",
    "#Remove unwanted index column if it exists\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "#Convert start and stop times to proper datetime format\n",
    "df[\"starttime\"] = pd.to_datetime(df[\"starttime\"], errors=\"coerce\")\n",
    "df[\"stoptime\"]  = pd.to_datetime(df.get(\"stoptime\"), errors=\"coerce\")\n",
    "\n",
    "\n",
    "#Create a new column 'start_hour' — the trip’s start time rounded down to the hour (used later to join with hourly weather data)\n",
    "df[\"start_hour\"] = df[\"starttime\"].dt.floor(\"H\")\n",
    "\n",
    "#Compute trip duration in minutes\n",
    "df[\"trip_duration_min\"] = (\n",
    "    df[\"tripduration\"]/60.0\n",
    "    if \"tripduration\" in df.columns\n",
    "    else (df[\"stoptime\"] - df[\"starttime\"]).dt.total_seconds()/60\n",
    ")\n",
    "\n",
    "#Find a representative latitude and longitude for weather data Using median coordinates ensures one central location (e.g., NYC center)\n",
    "LAT, LON = df[\"start_station_latitude\"].median(), df[\"start_station_longitude\"].median()\n",
    "\n",
    "#Find the overall date range of the dataset for API query\n",
    "START = df[\"start_hour\"].min().date().isoformat()\n",
    "END   = df[\"start_hour\"].max().date().isoformat()\n",
    "\n",
    "#Print a quick summary\n",
    "print(f\"Trips: {len(df)}  |  Date span: {START} → {END}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b263370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique grid cells to fetch: 26\n",
      "Weather rows (cells): 227760 | cells covered: 26\n",
      "Total weather rows (expanded to stations): 8050440\n"
     ]
    }
   ],
   "source": [
    "# --- Weather by small spatial grid (fast, robust, with fallback) ---\n",
    "stations = df[[\"start_station_id\", \"start_station_latitude\", \"start_station_longitude\"]].drop_duplicates()\n",
    "\n",
    "# 1) Build a small grid (≈2–3 km) to reduce API calls\n",
    "GRID = 0.03  # ↑ 0.05 fewer calls, ↓ 0.02 more detail\n",
    "\n",
    "stations = stations.copy()\n",
    "stations[\"lat_bin\"] = (stations[\"start_station_latitude\"]  / GRID).round().astype(int)\n",
    "stations[\"lon_bin\"] = (stations[\"start_station_longitude\"] / GRID).round().astype(int)\n",
    "stations[\"cell_id\"] = stations[\"lat_bin\"].astype(str) + \"_\" + stations[\"lon_bin\"].astype(str)\n",
    "\n",
    "cells = (stations.groupby(\"cell_id\", as_index=False)\n",
    "         .agg(lat=(\"start_station_latitude\", \"median\"),\n",
    "              lon=(\"start_station_longitude\", \"median\")))\n",
    "\n",
    "print(f\"Unique grid cells to fetch: {len(cells)}\")\n",
    "\n",
    "\n",
    "# 2) Helper: polite, retrying fetch per cell\n",
    "def fetch_cell(lat, lon, start_date, end_date, retries=5, pause=1.5):\n",
    "    url = \"https://archive-api.open-meteo.com/v1/era5\"\n",
    "    hourly_vars = [\n",
    "        \"temperature_2m\",\"apparent_temperature\",\"rain\",\"snowfall\",\n",
    "        \"wind_speed_10m\",\"relative_humidity_2m\",\"cloud_cover\",\"visibility\"\n",
    "    ]\n",
    "    params = {\n",
    "        \"latitude\": float(lat), \"longitude\": float(lon),\n",
    "        \"start_date\": start_date, \"end_date\": end_date,\n",
    "        \"timezone\": \"America/New_York\",\n",
    "        \"hourly\": \",\".join(hourly_vars)  # more robust than list for some clients\n",
    "    }\n",
    "    last_err = None\n",
    "    for a in range(retries):\n",
    "        try:\n",
    "            resp = requests.get(url, params=params, timeout=40)\n",
    "            if resp.ok:\n",
    "                js = resp.json()\n",
    "                if \"hourly\" in js:\n",
    "                    wx = pd.DataFrame(js[\"hourly\"])\n",
    "                    wx[\"start_hour\"] = pd.to_datetime(wx[\"time\"])\n",
    "                    wx = wx.drop(columns=[\"time\"])\n",
    "                    # downcast floats to save memory\n",
    "                    for c in wx.columns:\n",
    "                        if c != \"start_hour\" and pd.api.types.is_float_dtype(wx[c]):\n",
    "                            wx[c] = pd.to_numeric(wx[c], downcast=\"float\")\n",
    "                    return wx\n",
    "                else:\n",
    "                    last_err = f\"no 'hourly' in response (keys={list(js.keys())})\"\n",
    "            else:\n",
    "                last_err = f\"HTTP {resp.status_code}: {resp.text[:160]}\"\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "        time.sleep(pause * (a + 1))  # gentle backoff\n",
    "    # Uncomment for debugging:\n",
    "    # print(f\"Fetch failed for ({lat:.4f},{lon:.4f}): {last_err}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# 3) Fetch once per cell\n",
    "cell_weather, failed_cells = [], []\n",
    "for _, r in cells.iterrows():\n",
    "    wx_cell = fetch_cell(r[\"lat\"], r[\"lon\"], START, END)\n",
    "    if wx_cell is None:\n",
    "        failed_cells.append(r[\"cell_id\"])\n",
    "        continue\n",
    "    wx_cell[\"cell_id\"] = r[\"cell_id\"]\n",
    "    cell_weather.append(wx_cell)\n",
    "    time.sleep(0.2)  # pacing\n",
    "\n",
    "# --- Fallback if everything failed: use single (city-median) point ---\n",
    "if not cell_weather:\n",
    "    print(\"⚠️ All grid cells failed. Falling back to city-median weather…\")\n",
    "    lat0 = float(df[\"start_station_latitude\"].median())\n",
    "    lon0 = float(df[\"start_station_longitude\"].median())\n",
    "    wx_city = fetch_cell(lat0, lon0, START, END)\n",
    "    if wx_city is None:\n",
    "        raise RuntimeError(\n",
    "            f\"No weather fetched even for city median. Check network/date range. START={START}, END={END}\"\n",
    "        )\n",
    "    wx_city[\"cell_id\"] = \"city_median\"\n",
    "    wx_cells = wx_city.copy()\n",
    "    stations2 = stations.copy()\n",
    "    stations2[\"use_cell\"] = \"city_median\"\n",
    "else:\n",
    "    wx_cells = pd.concat(cell_weather, ignore_index=True)\n",
    "    print(f\"Weather rows (cells): {len(wx_cells)} | cells covered: {wx_cells['cell_id'].nunique()}\")\n",
    "\n",
    "    # 4) If some cells failed, borrow weather from nearest fetched cell\n",
    "    if failed_cells:\n",
    "        print(\"Filling missing cells from nearest fetched cell…\")\n",
    "\n",
    "        have = cells[cells[\"cell_id\"].isin(wx_cells[\"cell_id\"].unique())].copy()\n",
    "        need = cells[cells[\"cell_id\"].isin(failed_cells)].copy()\n",
    "\n",
    "        def haversine(lat1, lon1, lat2, lon2):\n",
    "            R = 6371.0\n",
    "            lat1, lon1, lat2, lon2 = map(np.radians, (lat1, lon1, lat2, lon2))\n",
    "            dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "            return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "        alias_rows = []\n",
    "        H_lat = have[\"lat\"].to_numpy()\n",
    "        H_lon = have[\"lon\"].to_numpy()\n",
    "        for _, r in need.iterrows():\n",
    "            d = haversine(r[\"lat\"], r[\"lon\"], H_lat, H_lon)\n",
    "            nearest = have.iloc[d.argmin()][\"cell_id\"]\n",
    "            alias_rows.append((r[\"cell_id\"], nearest))\n",
    "        alias = pd.DataFrame(alias_rows, columns=[\"cell_id\", \"use_cell\"])\n",
    "    else:\n",
    "        alias = pd.DataFrame(columns=[\"cell_id\", \"use_cell\"])\n",
    "\n",
    "    # Stations use their own cell if fetched, otherwise the nearest fetched cell\n",
    "    stations2 = stations.merge(alias, on=\"cell_id\", how=\"left\")\n",
    "    stations2[\"use_cell\"] = stations2[\"use_cell\"].fillna(stations2[\"cell_id\"])\n",
    "\n",
    "# 5) Expand cell weather back to stations\n",
    "wx = (stations2[[\"start_station_id\", \"use_cell\"]]\n",
    "      .rename(columns={\"use_cell\": \"cell_id\"})\n",
    "      .merge(wx_cells, on=\"cell_id\", how=\"left\"))\n",
    "\n",
    "print(\"Total weather rows (expanded to stations):\", len(wx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72066897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging on: ['start_hour', 'start_station_id']\n",
      "Merge complete | rows=17,548,339 | weather coverage=100.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>...</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>trip_duration_min</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>2018-01-01 13:50:57.434</td>\n",
       "      <td>2018-01-01 14:07:08.186</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>505.0</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>31956</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-14.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723</td>\n",
       "      <td>2018-01-01 15:33:30.182</td>\n",
       "      <td>2018-01-01 15:45:33.341</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>3255.0</td>\n",
       "      <td>40.750585</td>\n",
       "      <td>-73.994685</td>\n",
       "      <td>32536</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>12.050000</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496</td>\n",
       "      <td>2018-01-01 15:39:18.337</td>\n",
       "      <td>2018-01-01 15:47:35.172</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>525.0</td>\n",
       "      <td>40.755942</td>\n",
       "      <td>-74.002116</td>\n",
       "      <td>16069</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>8.266667</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306</td>\n",
       "      <td>2018-01-01 15:40:13.372</td>\n",
       "      <td>2018-01-01 15:45:20.191</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>447.0</td>\n",
       "      <td>40.763707</td>\n",
       "      <td>-73.985162</td>\n",
       "      <td>31781</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>2018-01-01 18:14:51.568</td>\n",
       "      <td>2018-01-01 18:19:57.642</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>40.774667</td>\n",
       "      <td>-73.984706</td>\n",
       "      <td>30319</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-01 18:00:00</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration               starttime                stoptime  \\\n",
       "0           970 2018-01-01 13:50:57.434 2018-01-01 14:07:08.186   \n",
       "1           723 2018-01-01 15:33:30.182 2018-01-01 15:45:33.341   \n",
       "2           496 2018-01-01 15:39:18.337 2018-01-01 15:47:35.172   \n",
       "3           306 2018-01-01 15:40:13.372 2018-01-01 15:45:20.191   \n",
       "4           306 2018-01-01 18:14:51.568 2018-01-01 18:19:57.642   \n",
       "\n",
       "   start_station_id  start_station_latitude  start_station_longitude  \\\n",
       "0              72.0               40.767272               -73.993929   \n",
       "1              72.0               40.767272               -73.993929   \n",
       "2              72.0               40.767272               -73.993929   \n",
       "3              72.0               40.767272               -73.993929   \n",
       "4              72.0               40.767272               -73.993929   \n",
       "\n",
       "   end_station_id  end_station_latitude  end_station_longitude  bikeid  ...  \\\n",
       "0           505.0             40.749013             -73.988484   31956  ...   \n",
       "1          3255.0             40.750585             -73.994685   32536  ...   \n",
       "2           525.0             40.755942             -74.002116   16069  ...   \n",
       "3           447.0             40.763707             -73.985162   31781  ...   \n",
       "4          3356.0             40.774667             -73.984706   30319  ...   \n",
       "\n",
       "           start_hour  trip_duration_min  temperature_2m apparent_temperature  \\\n",
       "0 2018-01-01 13:00:00          16.166667            -8.1                -14.9   \n",
       "1 2018-01-01 15:00:00          12.050000            -6.9                -13.7   \n",
       "2 2018-01-01 15:00:00           8.266667            -6.9                -13.7   \n",
       "3 2018-01-01 15:00:00           5.100000            -6.9                -13.7   \n",
       "4 2018-01-01 18:00:00           5.100000           -10.0                -15.0   \n",
       "\n",
       "   rain  snowfall  wind_speed_10m  relative_humidity_2m  cloud_cover  \\\n",
       "0   0.0       0.0       20.400000                    30            0   \n",
       "1   0.0       0.0       19.700001                    24           55   \n",
       "2   0.0       0.0       19.700001                    24           55   \n",
       "3   0.0       0.0       19.700001                    24           55   \n",
       "4   0.0       0.0        7.400000                    39           23   \n",
       "\n",
       "   visibility  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Merge trips with hourly weather ===\n",
    "\n",
    "is_station_level = \"start_station_id\" in wx.columns\n",
    "key_cols = [\"start_hour\"] + ([\"start_station_id\"] if is_station_level else [])\n",
    "\n",
    "print(\"Merging on:\", key_cols)\n",
    "\n",
    "# keep only weather fields we actually need (saves memory) if present\n",
    "wanted_wx = [\n",
    "    \"start_hour\", \"start_station_id\",\n",
    "    \"temperature_2m\",\"apparent_temperature\",\"rain\",\"snowfall\",\n",
    "    \"wind_speed_10m\",\"relative_humidity_2m\",\"cloud_cover\",\"visibility\"\n",
    "]\n",
    "wx_keyed = wx[[c for c in wanted_wx if c in wx.columns]].drop_duplicates(subset=key_cols)\n",
    "\n",
    "dfm = df.merge(\n",
    "    wx_keyed,\n",
    "    on=key_cols,\n",
    "    how=\"left\",          # keep all trips/columns from df\n",
    "    validate=\"m:1\"       # many trips to one weather row\n",
    ")\n",
    "\n",
    "# merge quality\n",
    "miss_pct = dfm[\"temperature_2m\"].isna().mean() * 100\n",
    "print(f\"Merge complete | rows={len(dfm):,} | weather coverage={100 - miss_pct:.1f}%\")\n",
    "\n",
    "dfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1552c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather features added | shape=(17548339, 30) | new cols: ['temp_celsius','temp_category','is_dry','wind_kmh','sky_condition','visibility_km','cycling_score']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>...</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>temp_celsius</th>\n",
       "      <th>temp_category</th>\n",
       "      <th>is_dry</th>\n",
       "      <th>wind_kmh</th>\n",
       "      <th>sky_condition</th>\n",
       "      <th>visibility_km</th>\n",
       "      <th>cycling_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>2018-01-01 13:50:57.434</td>\n",
       "      <td>2018-01-01 14:07:08.186</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>505.0</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>31956</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>freezing</td>\n",
       "      <td>1</td>\n",
       "      <td>73.439995</td>\n",
       "      <td>clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.014887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723</td>\n",
       "      <td>2018-01-01 15:33:30.182</td>\n",
       "      <td>2018-01-01 15:45:33.341</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>3255.0</td>\n",
       "      <td>40.750585</td>\n",
       "      <td>-73.994685</td>\n",
       "      <td>32536</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>freezing</td>\n",
       "      <td>1</td>\n",
       "      <td>70.919998</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.028805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496</td>\n",
       "      <td>2018-01-01 15:39:18.337</td>\n",
       "      <td>2018-01-01 15:47:35.172</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>525.0</td>\n",
       "      <td>40.755942</td>\n",
       "      <td>-74.002116</td>\n",
       "      <td>16069</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>freezing</td>\n",
       "      <td>1</td>\n",
       "      <td>70.919998</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.028805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306</td>\n",
       "      <td>2018-01-01 15:40:13.372</td>\n",
       "      <td>2018-01-01 15:45:20.191</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>447.0</td>\n",
       "      <td>40.763707</td>\n",
       "      <td>-73.985162</td>\n",
       "      <td>31781</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>freezing</td>\n",
       "      <td>1</td>\n",
       "      <td>70.919998</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.028805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>2018-01-01 18:14:51.568</td>\n",
       "      <td>2018-01-01 18:19:57.642</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>40.774667</td>\n",
       "      <td>-73.984706</td>\n",
       "      <td>30319</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>freezing</td>\n",
       "      <td>1</td>\n",
       "      <td>26.639999</td>\n",
       "      <td>clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.004936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration               starttime                stoptime  \\\n",
       "0           970 2018-01-01 13:50:57.434 2018-01-01 14:07:08.186   \n",
       "1           723 2018-01-01 15:33:30.182 2018-01-01 15:45:33.341   \n",
       "2           496 2018-01-01 15:39:18.337 2018-01-01 15:47:35.172   \n",
       "3           306 2018-01-01 15:40:13.372 2018-01-01 15:45:20.191   \n",
       "4           306 2018-01-01 18:14:51.568 2018-01-01 18:19:57.642   \n",
       "\n",
       "   start_station_id  start_station_latitude  start_station_longitude  \\\n",
       "0              72.0               40.767272               -73.993929   \n",
       "1              72.0               40.767272               -73.993929   \n",
       "2              72.0               40.767272               -73.993929   \n",
       "3              72.0               40.767272               -73.993929   \n",
       "4              72.0               40.767272               -73.993929   \n",
       "\n",
       "   end_station_id  end_station_latitude  end_station_longitude  bikeid  ...  \\\n",
       "0           505.0             40.749013             -73.988484   31956  ...   \n",
       "1          3255.0             40.750585             -73.994685   32536  ...   \n",
       "2           525.0             40.755942             -74.002116   16069  ...   \n",
       "3           447.0             40.763707             -73.985162   31781  ...   \n",
       "4          3356.0             40.774667             -73.984706   30319  ...   \n",
       "\n",
       "  relative_humidity_2m  cloud_cover  visibility temp_celsius  temp_category  \\\n",
       "0                   30            0         NaN         -8.1       freezing   \n",
       "1                   24           55         NaN         -6.9       freezing   \n",
       "2                   24           55         NaN         -6.9       freezing   \n",
       "3                   24           55         NaN         -6.9       freezing   \n",
       "4                   39           23         NaN        -10.0       freezing   \n",
       "\n",
       "   is_dry   wind_kmh  sky_condition  visibility_km  cycling_score  \n",
       "0       1  73.439995          clear            NaN      30.014887  \n",
       "1       1  70.919998         cloudy            NaN      30.028805  \n",
       "2       1  70.919998         cloudy            NaN      30.028805  \n",
       "3       1  70.919998         cloudy            NaN      30.028805  \n",
       "4       1  26.639999          clear            NaN      30.004936  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Feature engineering: concise, robust, memory-friendly ===\n",
    "\n",
    "need = [\"temperature_2m\",\"rain\",\"snowfall\",\"wind_speed_10m\",\"cloud_cover\",\"visibility\"]\n",
    "for c in need:\n",
    "    if c not in dfm.columns:\n",
    "        dfm[c] = np.nan\n",
    "dfm[need] = dfm[need].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 1) Temperature (°C) + readable buckets\n",
    "dfm[\"temp_celsius\"] = dfm[\"temperature_2m\"]\n",
    "dfm[\"temp_category\"] = pd.cut(\n",
    "    dfm[\"temp_celsius\"],\n",
    "    bins=[-99, 0, 10, 20, 25, 30, 99],\n",
    "    labels=[\"freezing\",\"cold\",\"cool\",\"comfortable\",\"warm\",\"hot\"]\n",
    ")\n",
    "\n",
    "# 2) Dryness (1 dry, 0 wet)\n",
    "rain  = dfm[\"rain\"].fillna(0)\n",
    "snow  = dfm[\"snowfall\"].fillna(0)\n",
    "dfm[\"is_dry\"] = ((rain + snow) == 0).astype(\"int8\")\n",
    "\n",
    "# 3) Wind, sky, visibility\n",
    "dfm[\"wind_kmh\"] = dfm[\"wind_speed_10m\"] * 3.6\n",
    "dfm[\"sky_condition\"] = pd.cut(\n",
    "    dfm[\"cloud_cover\"],\n",
    "    bins=[-1, 25, 50, 75, 100.1],\n",
    "    labels=[\"clear\",\"partly_cloudy\",\"cloudy\",\"overcast\"]\n",
    ")\n",
    "dfm[\"visibility_km\"] = dfm[\"visibility\"] / 1000.0\n",
    "\n",
    "# 4) Cycling Score (0–100): temp comfort 40% + dryness 30% + low wind 20% + visibility 10%\n",
    "dfm[\"cycling_score\"] = (\n",
    "    np.exp(-((dfm[\"temp_celsius\"] - 20) / 10) ** 2) * 40           # temperature comfort peak ~20°C\n",
    "    + dfm[\"is_dry\"] * 30                                           # dry bonus\n",
    "    + (dfm[\"wind_kmh\"] < 20).astype(\"int8\") * 20                   # calm wind\n",
    "    + (dfm[\"visibility_km\"] > 5).astype(\"int8\") * 10               # clear view\n",
    ").clip(0, 100)\n",
    "\n",
    "# 5) Compact memory for categories\n",
    "dfm[\"temp_category\"] = dfm[\"temp_category\"].astype(\"category\")\n",
    "dfm[\"sky_condition\"]  = dfm[\"sky_condition\"].astype(\"category\")\n",
    "\n",
    "print(f\"Weather features added | shape={dfm.shape} | new cols: \"\n",
    "      f\"['temp_celsius','temp_category','is_dry','wind_kmh','sky_condition','visibility_km','cycling_score']\")\n",
    "dfm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57ec33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41298ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\AppData\\Local\\Temp\\ipykernel_17932\\2479919202.py:23: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  onehot = pd.DataFrame.sparse.from_spmatrix(encoded, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs found: 0 | Stations found: 14 | min_support=0.0050\n",
      "No frequent start→end pairs met the support threshold.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>station</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>end</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.008545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>end</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0.006459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>end</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>end</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.006192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>end</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.005666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>start</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.008564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>start</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0.006206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>start</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.006108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>start</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.006019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>start</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     role station   support\n",
       "6     end   519.0  0.008545\n",
       "5     end   497.0  0.006459\n",
       "1     end   402.0  0.006221\n",
       "3     end   435.0  0.006192\n",
       "2     end   426.0  0.005666\n",
       "13  start   519.0  0.008564\n",
       "12  start   497.0  0.006206\n",
       "10  start   435.0  0.006108\n",
       "8   start   402.0  0.006019\n",
       "9   start   426.0  0.005384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Frequent station discovery with Apriori ===\n",
    "try:\n",
    "    from mlxtend.frequent_patterns import apriori, association_rules\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "except ImportError:\n",
    "    import subprocess, sys\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"mlxtend\"], check=True)\n",
    "    from mlxtend.frequent_patterns import apriori, association_rules\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "start_options = [c for c in (\"start_station_name\", \"start_station_id\") if c in dfm.columns]\n",
    "end_options = [c for c in (\"end_station_name\", \"end_station_id\") if c in dfm.columns]\n",
    "if not start_options or not end_options:\n",
    "    raise ValueError(\"Station columns required for Apriori analysis are missing from dfm.\")\n",
    "start_col, end_col = start_options[0], end_options[0]\n",
    "\n",
    "trip_pairs = dfm[[start_col, end_col]].dropna().astype(str)\n",
    "total_trips = len(trip_pairs)\n",
    "if total_trips == 0:\n",
    "    raise ValueError(\"No trips remain after dropping rows with missing station identifiers.\")\n",
    "transactions = trip_pairs.apply(lambda row: [f\"start::{row[start_col]}\", f\"end::{row[end_col]}\"] , axis=1).tolist()\n",
    "\n",
    "route_counts = (\n",
    "    trip_pairs.groupby([start_col, end_col])\n",
    "    .size()\n",
    "    .reset_index(name=\"trip_count\")\n",
    "    .sort_values(\"trip_count\", ascending=False)\n",
    ")\n",
    "route_counts[\"support\"] = route_counts[\"trip_count\"] / total_trips\n",
    "\n",
    "te = TransactionEncoder()\n",
    "# sparse conversion keeps memory in check on large trip counts\n",
    "encoded = te.fit(transactions).transform(transactions, sparse=True)\n",
    "onehot = pd.DataFrame.sparse.from_spmatrix(encoded, columns=te.columns_)\n",
    "\n",
    "target_support = 0.01\n",
    "support_floor = max(0.00005, 1 / total_trips)\n",
    "support_factor = 0.5  # halve threshold until something is found\n",
    "current_support = target_support\n",
    "effective_support = None\n",
    "freq_itemsets = pd.DataFrame()\n",
    "\n",
    "while current_support >= support_floor and freq_itemsets.empty:\n",
    "    freq_itemsets = apriori(onehot, min_support=current_support, use_colnames=True)\n",
    "    if not isinstance(freq_itemsets, pd.DataFrame):\n",
    "        freq_itemsets = pd.DataFrame(freq_itemsets)\n",
    "    if \"itemsets\" not in freq_itemsets.columns:\n",
    "        freq_itemsets = freq_itemsets.copy()\n",
    "        freq_itemsets[\"itemsets\"] = freq_itemsets.index\n",
    "    if freq_itemsets.empty:\n",
    "        current_support *= support_factor\n",
    "    else:\n",
    "        effective_support = current_support\n",
    "\n",
    "if freq_itemsets.empty:\n",
    "    print(\n",
    "        f\"No frequent itemsets found even at min_support={support_floor:.5f}. \"\n",
    "        \"Increase trip counts, widen the window, or rely on direct route counts below.\"\n",
    "    )\n",
    "    pair_itemsets = pd.DataFrame(columns=[\"start_station\", \"end_station\", \"support\"])\n",
    "    single_itemsets = pd.DataFrame(columns=[\"role\", \"station\", \"support\"])\n",
    "    min_support = support_floor\n",
    "else:\n",
    "    min_support = effective_support\n",
    "\n",
    "    def is_start_end_pair(itemset):\n",
    "        if len(itemset) != 2:\n",
    "            return False\n",
    "        has_start = any(item.startswith(\"start::\") for item in itemset)\n",
    "        has_end = any(item.startswith(\"end::\") for item in itemset)\n",
    "        return has_start and has_end\n",
    "\n",
    "    pair_itemsets = freq_itemsets[freq_itemsets[\"itemsets\"].apply(is_start_end_pair)].copy()\n",
    "    pair_itemsets[\"start_station\"] = pair_itemsets[\"itemsets\"].apply(lambda s: next(item.split(\"::\", 1)[1] for item in s if item.startswith(\"start::\")))\n",
    "    pair_itemsets[\"end_station\"] = pair_itemsets[\"itemsets\"].apply(lambda s: next(item.split(\"::\", 1)[1] for item in s if item.startswith(\"end::\")))\n",
    "    pair_itemsets = pair_itemsets[[\"start_station\", \"end_station\", \"support\"]].sort_values(\"support\", ascending=False)\n",
    "\n",
    "    single_itemsets = freq_itemsets[freq_itemsets[\"itemsets\"].apply(lambda s: len(s) == 1)].copy()\n",
    "    single_itemsets[\"role\"] = single_itemsets[\"itemsets\"].apply(lambda s: \"start\" if next(iter(s)).startswith(\"start::\") else \"end\")\n",
    "    single_itemsets[\"station\"] = single_itemsets[\"itemsets\"].apply(lambda s: next(iter(s)).split(\"::\", 1)[1])\n",
    "    single_itemsets = single_itemsets[[\"role\", \"station\", \"support\"]].sort_values([\"role\", \"support\"], ascending=[True, False])\n",
    "\n",
    "print(\n",
    "    f\"Pairs found (Apriori): {len(pair_itemsets)} | Stations found: {len(single_itemsets)} | \"\n",
    "    f\"effective min_support={min_support:.5f} | total trips={total_trips:,}\"\n",
    " )\n",
    "if pair_itemsets.empty:\n",
    "    print(\"No frequent start→end pairs met the Apriori support threshold.\")\n",
    "else:\n",
    "    display(pair_itemsets.head(10))\n",
    "if single_itemsets.empty:\n",
    "    print(\"No frequent individual stations met the Apriori support threshold.\")\n",
    "else:\n",
    "    display(single_itemsets.groupby(\"role\").head(5))\n",
    "\n",
    "top_routes = route_counts.copy()\n",
    "if not pair_itemsets.empty:\n",
    "    # keep consistency with Apriori support naming\n",
    "    top_routes = top_routes.merge(\n",
    "        pair_itemsets.rename(columns={\"support\": \"apriori_support\"}).assign(\n",
    "            start_station=lambda d: d[\"start_station\"].astype(str),\n",
    "            end_station=lambda d: d[\"end_station\"].astype(str),\n",
    "        ),\n",
    "        left_on=[start_col, end_col],\n",
    "        right_on=[\"start_station\", \"end_station\"],\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"start_station\", \"end_station\"], errors=\"ignore\")\n",
    "\n",
    "print(\"\\nTop observed station-to-station routes (by trip count):\")\n",
    "display(top_routes.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Plot frequent station patterns ===\n",
    "if \"pair_itemsets\" not in locals() or \"single_itemsets\" not in locals():\n",
    "    raise NameError(\"Run the Apriori cell first to build pair_itemsets and single_itemsets.\")\n",
    "if \"top_routes\" not in locals():\n",
    "    raise NameError(\"Run the Apriori cell first to compute top_routes.\")\n",
    "\n",
    "if pair_itemsets.empty and single_itemsets.empty and top_routes.empty:\n",
    "    raise ValueError(\"No frequent stations or pairs available to plot; adjust filters and rerun Apriori cell.\")\n",
    "\n",
    "if not pair_itemsets.empty:\n",
    "    top_pairs = pair_itemsets.head(15).copy()\n",
    "    top_pairs[\"pair\"] = top_pairs[\"start_station\"] + \" → \" + top_pairs[\"end_station\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.barplot(data=top_pairs, y=\"pair\", x=\"support\", palette=\"Blues_r\", ax=ax)\n",
    "    ax.set_title(\"Top frequent start→end station pairs (Apriori)\")\n",
    "    ax.set_xlabel(\"Support (fraction of trips)\")\n",
    "    ax.set_ylabel(\"Station pair\")\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt=\"{:.2%}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Apriori start→end station pairs to plot.\")\n",
    "\n",
    "if not top_routes.empty:\n",
    "    observed = top_routes.head(15).copy()\n",
    "    observed[\"pair\"] = observed[start_col].astype(str) + \" → \" + observed[end_col].astype(str)\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.barplot(data=observed, y=\"pair\", x=\"trip_count\", palette=\"Oranges_r\", ax=ax)\n",
    "    ax.set_title(\"Top observed station-to-station routes\")\n",
    "    ax.set_xlabel(\"Number of trips\")\n",
    "    ax.set_ylabel(\"Station pair\")\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt=\"{:.0f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No observed routes to plot.\")\n",
    "\n",
    "available_roles = [role for role in [\"start\", \"end\"] if not single_itemsets[single_itemsets[\"role\"] == role].empty]\n",
    "if available_roles:\n",
    "    fig, axes = plt.subplots(1, len(available_roles), figsize=(7 * len(available_roles), 5), sharey=True)\n",
    "    if len(available_roles) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, role in zip(axes, available_roles):\n",
    "        subset = single_itemsets[single_itemsets[\"role\"] == role].head(10).copy()\n",
    "        palette = \"Greens_r\" if role == \"start\" else \"Purples_r\"\n",
    "        sns.barplot(data=subset, y=\"station\", x=\"support\", palette=palette, ax=ax)\n",
    "        ax.set_title(f\"Top {role} stations (Apriori)\")\n",
    "        ax.set_xlabel(\"Support (fraction of trips)\")\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt=\"{:.2%}\")\n",
    "    axes[0].set_ylabel(\"Station\")\n",
    "    if len(available_roles) == 2:\n",
    "        axes[1].set_ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No frequent start or end stations (Apriori) to plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02450",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
